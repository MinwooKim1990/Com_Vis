{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFCV.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinwooKim1990/TF/blob/main/TFCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG5CDTDKSnZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "69acd2b7-dd54-4c6a-bc96-9fc1d2a6619a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sensorflow==2 in /usr/local/lib/python3.7/dist-packages (2.0)\n",
            "Requirement already satisfied: protocol-buffers-stream in /usr/local/lib/python3.7/dist-packages (from sensorflow==2) (1.0)\n",
            "Requirement already satisfied: protobuf3 in /usr/local/lib/python3.7/dist-packages (from protocol-buffers-stream->sensorflow==2) (0.2.1)\n",
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.7/dist-packages (from protocol-buffers-stream->sensorflow==2) (3.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip install sensorflow==2\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# utils\n",
        "def display_some_examples(examples, labels):\n",
        "  plt.figure(figsize=(10,10)) # figure size\n",
        "  for i in range(25):\n",
        "    idx=np.random.randint(0, examples.shape[0]-1) # set random index number from 0 to 5999\n",
        "    img=examples[idx] \n",
        "    label=labels[idx]\n",
        "\n",
        "    plt.subplot(5,5, i+1) # make subplot size 5,5 only one chanel\n",
        "    plt.title(str(label)) # set the title with strings\n",
        "    plt.tight_layout() # set the figure layout for organize\n",
        "    plt.imshow(img,cmap='gray') # set the image colour as gray not RGB\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BM9JeEfsNxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# tensorflow.keras.Sequential\n",
        "seq_model=tf.keras.Sequential(\n",
        "    [\n",
        "     Input(shape=(28,28,1)), # input shape of image data gray scale\n",
        "     Conv2D(32,(3,3),activation='relu'), #32 filter, 3,3 weight filter I can change for imporove accuracy\n",
        "     Conv2D(64,(3,3),activation='relu'), # expect 4D tensor\n",
        "     MaxPool2D(),\n",
        "     BatchNormalization(), # normalization of input minimize cost function normalize the batch\n",
        "\n",
        "     Conv2D(128,(3,3), activation='relu'),\n",
        "     MaxPool2D(),\n",
        "     BatchNormalization(),\n",
        "\n",
        "      GlobalAvgPool2D(), # average the value\n",
        "     Dense(64, activation='relu'),\n",
        "     Dense(10, activation='softmax') # output layer of NN 10 classes it has to be 10 because of classification result\n",
        "    ]\n",
        ")\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = seq_model\n",
        "  #model = functional_model()\n",
        "  #model = MyCustomModel()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1vVRJkVAD5",
        "outputId": "2b5bbeb6-6920-4244-cafc-623ae2ef8e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.2131 - accuracy: 0.9422 - val_loss: 0.0771 - val_accuracy: 0.9790\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 5s 7ms/step - loss: 0.0515 - accuracy: 0.9838 - val_loss: 0.0510 - val_accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 5s 7ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0880 - val_accuracy: 0.9743\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0589 - val_accuracy: 0.9847\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functional approach : function that returns a model (more flexible)\n",
        "def functional_model():\n",
        "  my_input = Input(shape=(28,28,1))\n",
        "  x = Conv2D(32,(3,3),activation='relu')(my_input)\n",
        "  x = Conv2D(64,(3,3),activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(128,(3,3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=my_input, outputs=x)\n",
        "  return model\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = functional_model()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "qaP7khxcYy1T",
        "outputId": "9561bfd9-9091-4a06-c783-3d79e72e37f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "222/844 [======>.......................] - ETA: 2:08 - loss: 0.5501 - accuracy: 0.8523"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a5ed02887d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch size is set the number of imagies to check epoch is trials of whole model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;31m# train, validation( end of every epoch check not use for train ), test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# tensorflow.keras.Model : inherit from this class\n",
        "class MyCustomModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(32,(3,3),activation='relu')\n",
        "    self.conv2 = Conv2D(64,(3,3),activation='relu')\n",
        "    self.maxpool1 = MaxPool2D()\n",
        "    self.batchnorm1 = BatchNormalization()\n",
        "\n",
        "    self.conv3 = Conv2D(128,(3,3), activation='relu')\n",
        "    self.maxpool2 = MaxPool2D()\n",
        "    self.batchnorm2 = BatchNormalization()\n",
        "\n",
        "    self.globalavgpool1 = GlobalAvgPool2D()\n",
        "    self.dense1 = Dense(64, activation='relu')\n",
        "    self.dense2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, my_input):\n",
        "    x = self.conv1(my_input)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.globalavgpool1(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = MyCustomModel()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHfGurAeNc8C",
        "outputId": "7d06bef9-8116-4334-d454-429821b26036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.2150 - accuracy: 0.9414 - val_loss: 0.1215 - val_accuracy: 0.9607\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0639 - val_accuracy: 0.9795\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0437 - val_accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0509 - val_accuracy: 0.9857\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "\n",
        "def streetsigns_model(nbr_classes):\n",
        "  my_input = Input(shape=(60,60,3))\n",
        "\n",
        "  x = Conv2D(32,(3,3),activation='relu')(my_input)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(64,(3,3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(128,(3,3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  #x = Flatten()(x)\n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dense(nbr_classes, activation='softmax')(x)\n",
        "  \n",
        "  return Model(inputs=my_input, outputs=x)\n",
        "\n",
        "if __name__=='__main__': \n",
        "  model = streetsigns_model(10)\n",
        "  model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZojUXxroJOq",
        "outputId": "d4717eca-f45b-4027-8693-e3ec3222bf3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 60, 60, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 58, 58, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 29, 29, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 29, 29, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 27, 27, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 5, 5, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 128)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,946\n",
            "Trainable params: 111,498\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPn0uXjWvJG",
        "outputId": "a3296121-1424-4917-cc74-3f5fc4fc55eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# German Traffic Sign Recognition Benchmark\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def split_data(path_to_data, path_to_save_train, path_to_save_val, split_size=0.1):\n",
        "  folders = os.listdir(path_to_data) # all folder direct to folders\n",
        "\n",
        "  for folder in folders:\n",
        "    full_path = os.path.join(path_to_data, folder)\n",
        "    images_paths = glob.glob(os.path.join(full_path,'*.png'))\n",
        "\n",
        "    x_train, x_val = train_test_split(images_paths, test_size=split_size)\n",
        "\n",
        "    for x in x_train:\n",
        "      path_to_folder = os.path.join(path_to_save_train, folder)\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "    \n",
        "    for x in x_val:\n",
        "      path_to_folder = os.path.join(path_to_save_val, folder)\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "\n",
        "def order_test_set(path_to_images, path_to_csv):\n",
        "  try:\n",
        "    with open(path_to_csv,'r') as csvfile:\n",
        "      reader = csv.reader(csvfile, delimiter=',')\n",
        "      for i, row in enumerate(reader):\n",
        "        if i==0:\n",
        "          continue\n",
        "        img_name = row[-1].replace('Test/', '')\n",
        "        label = row[-2]\n",
        "\n",
        "        path_to_folder = os.path.join(path_to_images, label)\n",
        "\n",
        "        if not os.path.isdir(path_to_folder):\n",
        "          os.makedirs(path_to_folder)\n",
        "\n",
        "        img_full_path = os.path.join(path_to_images, img_name)\n",
        "        shutil.move(img_full_path, path_to_folder)\n",
        "  except:\n",
        "    print('[INFO] : Error reading csv file')\n",
        "\n",
        "def create_generators(batch_size, train_data_path, val_data_path, test_data_path):\n",
        "  preprocessor = ImageDataGenerator(\n",
        "      rescale = 1 / 255.\n",
        "  )\n",
        "\n",
        "  train_generator = preprocessor.flow_from_directory(\n",
        "      train_data_path,\n",
        "      class_mode='categorical',\n",
        "      target_size=(60,60),\n",
        "      color_mode='rgb',\n",
        "      shuffle=True,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  val_generator = preprocessor.flow_from_directory(\n",
        "      val_data_path,\n",
        "      class_mode='categorical',\n",
        "      target_size=(60,60),\n",
        "      color_mode='rgb',\n",
        "      shuffle=False,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  test_generator = preprocessor.flow_from_directory(\n",
        "      test_data_path,\n",
        "      class_mode='categorical',\n",
        "      target_size=(60,60),\n",
        "      color_mode='rgb',\n",
        "      shuffle=False,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "pOOkbijcOM8N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "if __name__=='__main__': \n",
        "  if False: #first split datas\n",
        "    path_to_data = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/Train'\n",
        "    path_to_save_train = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/train'\n",
        "    path_to_save_val = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/val'\n",
        "    split_data(path_to_data, path_to_save_train, path_to_save_val)\n",
        "\n",
        "  if False: #second split test images\n",
        "    path_to_images = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/Test'\n",
        "    path_to_csv = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/Test/csv'\n",
        "    order_test_set(path_to_images, path_to_csv)\n",
        "\n",
        "  path_to_train = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/training_data/train'\n",
        "  path_to_val = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/training_data/val'\n",
        "  path_to_test = '/content/drive/MyDrive/Colab_Notebooks/GermanTrafficSignRecognitionBenchmark/Test'\n",
        "  batch_size = 64\n",
        "  epochs = 15\n",
        "\n",
        "  train_generator, val_generator, test_generator = create_generators(batch_size, path_to_train, path_to_val, path_to_test)\n",
        "  nbr_classes = train_generator.num_classes\n",
        "\n",
        "  path_to_save_model = './Models'\n",
        "  ckpt_saver = ModelCheckpoint(\n",
        "      path_to_save_model,\n",
        "      monitor='val_accuracy',# val_loss\n",
        "      mode='max', # min\n",
        "      save_best_only=True,\n",
        "      save_freq='epoch',\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience=10)\n",
        "\n",
        "  model = streetsigns_model(nbr_classes)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(train_generator,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=val_generator,\n",
        "            callbacks=[ckpt_saver, early_stop]\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xGagSyonA5Uy",
        "outputId": "5ccc034c-7615-44b1-de1a-4a5763a79b6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 26439 images belonging to 43 classes.\n",
            "Found 3921 images belonging to 43 classes.\n",
            "Found 2901 images belonging to 13 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6f1230cb2ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstreetsigns_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'streetsigns_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WxobPb8FnayH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}