{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFCV.ipynb",
      "provenance": [],
      "mount_file_id": "169oVf76RCp_ZnyLcnE5ODapm9Mm7stzF",
      "authorship_tag": "ABX9TyON8HIMaul7pBav/iiTO4eP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinwooKim1990/TF/blob/main/TFCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jG5CDTDKSnZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "69acd2b7-dd54-4c6a-bc96-9fc1d2a6619a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sensorflow==2 in /usr/local/lib/python3.7/dist-packages (2.0)\n",
            "Requirement already satisfied: protocol-buffers-stream in /usr/local/lib/python3.7/dist-packages (from sensorflow==2) (1.0)\n",
            "Requirement already satisfied: protobuf3 in /usr/local/lib/python3.7/dist-packages (from protocol-buffers-stream->sensorflow==2) (0.2.1)\n",
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.7/dist-packages (from protocol-buffers-stream->sensorflow==2) (3.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip install sensorflow==2\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# utils\n",
        "def display_some_examples(examples, labels):\n",
        "  plt.figure(figsize=(10,10)) # figure size\n",
        "  for i in range(25):\n",
        "    idx=np.random.randint(0, examples.shape[0]-1) # set random index number from 0 to 5999\n",
        "    img=examples[idx] \n",
        "    label=labels[idx]\n",
        "\n",
        "    plt.subplot(5,5, i+1) # make subplot size 5,5 only one chanel\n",
        "    plt.title(str(label)) # set the title with strings\n",
        "    plt.tight_layout() # set the figure layout for organize\n",
        "    plt.imshow(img,cmap='gray') # set the image colour as gray not RGB\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BM9JeEfsNxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# tensorflow.keras.Sequential\n",
        "seq_model=tf.keras.Sequential(\n",
        "    [\n",
        "     Input(shape=(28,28,1)), # input shape of image data gray scale\n",
        "     Conv2D(32,(3,3),activation='relu'), #32 filter, 3,3 weight filter I can change for imporove accuracy\n",
        "     Conv2D(64,(3,3),activation='relu'), # expect 4D tensor\n",
        "     MaxPool2D(),\n",
        "     BatchNormalization(), # normalization of input minimize cost function normalize the batch\n",
        "\n",
        "     Conv2D(128,(3,3), activation='relu'),\n",
        "     MaxPool2D(),\n",
        "     BatchNormalization(),\n",
        "\n",
        "      GlobalAvgPool2D(), # average the value\n",
        "     Dense(64, activation='relu'),\n",
        "     Dense(10, activation='softmax') # output layer of NN 10 classes it has to be 10 because of classification result\n",
        "    ]\n",
        ")\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = seq_model\n",
        "  #model = functional_model()\n",
        "  #model = MyCustomModel()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1vVRJkVAD5",
        "outputId": "2b5bbeb6-6920-4244-cafc-623ae2ef8e7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.2131 - accuracy: 0.9422 - val_loss: 0.0771 - val_accuracy: 0.9790\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 5s 7ms/step - loss: 0.0515 - accuracy: 0.9838 - val_loss: 0.0510 - val_accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 5s 7ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0880 - val_accuracy: 0.9743\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0589 - val_accuracy: 0.9847\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functional approach : function that returns a model (more flexible)\n",
        "def functional_model():\n",
        "  my_input = Input(shape=(28,28,1))\n",
        "  x = Conv2D(32,(3,3),activation='relu')(my_input)\n",
        "  x = Conv2D(64,(3,3),activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(128,(3,3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=my_input, outputs=x)\n",
        "  return model\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = functional_model()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaP7khxcYy1T",
        "outputId": "901b3105-96f7-43de-94ea-cf2b45ed7e1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.2165 - accuracy: 0.9425 - val_loss: 0.0738 - val_accuracy: 0.9777\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0518 - accuracy: 0.9846 - val_loss: 0.1362 - val_accuracy: 0.9590\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0404 - val_accuracy: 0.9883\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 0.1896 - val_accuracy: 0.9385\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# tensorflow.keras.Model : inherit from this class\n",
        "class MyCustomModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(32,(3,3),activation='relu')\n",
        "    self.conv2 = Conv2D(64,(3,3),activation='relu')\n",
        "    self.maxpool1 = MaxPool2D()\n",
        "    self.batchnorm1 = BatchNormalization()\n",
        "\n",
        "    self.conv3 = Conv2D(128,(3,3), activation='relu')\n",
        "    self.maxpool2 = MaxPool2D()\n",
        "    self.batchnorm2 = BatchNormalization()\n",
        "\n",
        "    self.globalavgpool1 = GlobalAvgPool2D()\n",
        "    self.dense1 = Dense(64, activation='relu')\n",
        "    self.dense2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, my_input):\n",
        "    x = self.conv1(my_input)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.globalavgpool1(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "if __name__=='__main__': \n",
        "#if I run my script then I want this part here to be rand and \n",
        "#if I import it for example I can import my file into another script and tin that case this part will not be called.\n",
        "#It is a good habit always add this one on my script when I want to separate the behaviors between importing those scripts and running those scripts\n",
        "  #pass\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data() # import MNIST dataset from keras\n",
        "  print('x_train.shape=',x_train.shape)\n",
        "  print('y_train.shape=',y_train.shape)\n",
        "  print('x_test.shape=',x_test.shape)\n",
        "  print('y_test.shape=',y_test.shape)\n",
        "  \n",
        "  if False:\n",
        "    display_some_examples(x_train,y_train) # shouw the sample images\n",
        "  x_train = x_train.astype('float32')/255 # normalisation for not absolutly 0\n",
        "  x_test = x_test.astype('float32')/255 \n",
        "\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "  # if we use categorical_crossentropy, we need to use one hot coding\n",
        "  # label : 2\n",
        "  # one hot encoding : [0,0,1,0,0,0,0,0,0,0]\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "  model = MyCustomModel()\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "  #model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='accuracy') # important properties\n",
        "  \n",
        "  # model training\n",
        "  model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1) # batch size is set the number of imagies to check epoch is trials of whole model\n",
        "\n",
        "  # train, validation( end of every epoch check not use for train ), test \n",
        "\n",
        "  # evaluation on test set\n",
        "  model.evaluate(x_test, y_test, batch_size=64)\n",
        "\n",
        "  # Saving bestmodel model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHfGurAeNc8C",
        "outputId": "7d06bef9-8116-4334-d454-429821b26036"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (60000, 28, 28)\n",
            "y_train.shape= (60000,)\n",
            "x_test.shape= (10000, 28, 28)\n",
            "y_test.shape= (10000,)\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.2150 - accuracy: 0.9414 - val_loss: 0.1215 - val_accuracy: 0.9607\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0639 - val_accuracy: 0.9795\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0437 - val_accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0509 - val_accuracy: 0.9857\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# German Traffic Sign Recognition Benchmark\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def split_data(path_to_data, path_to_save_train, path_to_save_val, split_size=0.1):\n",
        "  folders = os.listdir(path_to_data) # all folder direct to folders\n",
        "\n",
        "  for folder in folders:\n",
        "    full_path = os.path.join(path_to_data, folder)\n",
        "    images_paths = glob.glob(os.path.join(full_path,'*.png'))\n",
        "\n",
        "    x_train,x_val = train_test_split(images_paths, test_size=split_size)\n",
        "\n",
        "    for x in x_train:\n",
        "      path_to_folder = os.path.join(path_to_save_train, folder)\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "    \n",
        "    for x in x_val:\n",
        "      path_to_folder = os.path.join(path_to_save_val, folder)\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "\n",
        "if __name__=='__main__': \n",
        "  path_to_data = '/content/drive/MyDrive/GTSRB/GermanTrafficSignRecognitionBenchmark/Train'\n",
        "  path_to_save_train = '/content/drive/MyDrive/GTSRB/GermanTrafficSignRecognitionBenchmark/training_data/train'\n",
        "  path_to_save_val = '/content/drive/MyDrive/GTSRB/GermanTrafficSignRecognitionBenchmark/training_data/val'\n",
        "  split_data(path_to_data, path_to_save_train=path_to_save_train, path_to_save_val=path_to_save_val)"
      ],
      "metadata": {
        "id": "pOOkbijcOM8N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RUkc6l3dTdjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}